{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "historic-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sufficient-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('singapore_trip_advisor_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "received-pregnancy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126021, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceramic-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "herbal-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103766, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "backed-webmaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVIEW_INDEX</th>\n",
       "      <th>REVIEW_DATE</th>\n",
       "      <th>REVIEW_RATING</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>REVIEW_BODY</th>\n",
       "      <th>DATE_OF_EXPERIENCE</th>\n",
       "      <th>TRIP_TYPE</th>\n",
       "      <th>REVIEW_CRAWLED_TIME</th>\n",
       "      <th>REVIEWER_NAME</th>\n",
       "      <th>HOME_COUNTRY</th>\n",
       "      <th>ATTRACTION_NAME</th>\n",
       "      <th>ATTRACTION_TYPE</th>\n",
       "      <th>ADDRESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>741832336</td>\n",
       "      <td>2020-01-29 00:00:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>Fabulous experience and an unforgettable day o...</td>\n",
       "      <td>2020-01-01 00:00:00.000</td>\n",
       "      <td>Couples</td>\n",
       "      <td>2020-01-29 12:01:27.012</td>\n",
       "      <td>Dreinog</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Cloud Forest</td>\n",
       "      <td>Leisure &amp; Recreation</td>\n",
       "      <td>18 Marina Gardens Drive | 18 Marina Gardens Dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>741819214</td>\n",
       "      <td>2020-01-29 00:00:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>Stunning</td>\n",
       "      <td>I wasnâ€™t sure what to expect but this was ab...</td>\n",
       "      <td>2020-01-01 00:00:00.000</td>\n",
       "      <td>Family</td>\n",
       "      <td>2020-01-29 11:30:13.663</td>\n",
       "      <td>3mcglynns</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Cloud Forest</td>\n",
       "      <td>Leisure &amp; Recreation</td>\n",
       "      <td>18 Marina Gardens Drive | 18 Marina Gardens Dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>741818972</td>\n",
       "      <td>2020-01-29 00:00:00.000</td>\n",
       "      <td>3</td>\n",
       "      <td>Another Chinatown</td>\n",
       "      <td>As every major city worldwide seems to have a ...</td>\n",
       "      <td>2020-01-01 00:00:00.000</td>\n",
       "      <td>Couples</td>\n",
       "      <td>2020-01-30 11:53:44.082</td>\n",
       "      <td>MR_Travels1920</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Chinatown</td>\n",
       "      <td>Precinct &amp; Street</td>\n",
       "      <td>Crot | Trengganu, Singapore 048942, Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>741881009</td>\n",
       "      <td>2020-01-29 00:00:00.000</td>\n",
       "      <td>4</td>\n",
       "      <td>Good lively place to visit</td>\n",
       "      <td>Busy lively place in the evening I visited. Go...</td>\n",
       "      <td>2020-01-01 00:00:00.000</td>\n",
       "      <td>Solo</td>\n",
       "      <td>2020-01-30 12:34:12.312</td>\n",
       "      <td>RaviA651</td>\n",
       "      <td>United States</td>\n",
       "      <td>Chinatown</td>\n",
       "      <td>Precinct &amp; Street</td>\n",
       "      <td>Crot | Trengganu, Singapore 048942, Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>741827762</td>\n",
       "      <td>2020-01-29 00:00:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>Great experience</td>\n",
       "      <td>Fabulous location and atmosphere. We only stop...</td>\n",
       "      <td>2020-01-01 00:00:00.000</td>\n",
       "      <td>Couples</td>\n",
       "      <td>2020-01-29 23:02:07.201</td>\n",
       "      <td>Dreinog</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Marina Bay</td>\n",
       "      <td>Precinct &amp; Street</td>\n",
       "      <td>Marina Boulevard, Singapore 018980, Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REVIEW_INDEX              REVIEW_DATE  REVIEW_RATING  \\\n",
       "0     741832336  2020-01-29 00:00:00.000              5   \n",
       "1     741819214  2020-01-29 00:00:00.000              5   \n",
       "2     741818972  2020-01-29 00:00:00.000              3   \n",
       "3     741881009  2020-01-29 00:00:00.000              4   \n",
       "4     741827762  2020-01-29 00:00:00.000              5   \n",
       "\n",
       "                 REVIEW_TITLE  \\\n",
       "0                    Fabulous   \n",
       "1                    Stunning   \n",
       "2           Another Chinatown   \n",
       "3  Good lively place to visit   \n",
       "4            Great experience   \n",
       "\n",
       "                                         REVIEW_BODY       DATE_OF_EXPERIENCE  \\\n",
       "0  Fabulous experience and an unforgettable day o...  2020-01-01 00:00:00.000   \n",
       "1  I wasnâ€™t sure what to expect but this was ab...  2020-01-01 00:00:00.000   \n",
       "2  As every major city worldwide seems to have a ...  2020-01-01 00:00:00.000   \n",
       "3  Busy lively place in the evening I visited. Go...  2020-01-01 00:00:00.000   \n",
       "4  Fabulous location and atmosphere. We only stop...  2020-01-01 00:00:00.000   \n",
       "\n",
       "  TRIP_TYPE      REVIEW_CRAWLED_TIME   REVIEWER_NAME    HOME_COUNTRY  \\\n",
       "0   Couples  2020-01-29 12:01:27.012         Dreinog  United Kingdom   \n",
       "1    Family  2020-01-29 11:30:13.663       3mcglynns       Australia   \n",
       "2   Couples  2020-01-30 11:53:44.082  MR_Travels1920  United Kingdom   \n",
       "3      Solo  2020-01-30 12:34:12.312        RaviA651   United States   \n",
       "4   Couples  2020-01-29 23:02:07.201         Dreinog  United Kingdom   \n",
       "\n",
       "  ATTRACTION_NAME       ATTRACTION_TYPE  \\\n",
       "0    Cloud Forest  Leisure & Recreation   \n",
       "1    Cloud Forest  Leisure & Recreation   \n",
       "2       Chinatown     Precinct & Street   \n",
       "3       Chinatown     Precinct & Street   \n",
       "4      Marina Bay     Precinct & Street   \n",
       "\n",
       "                                             ADDRESS  \n",
       "0  18 Marina Gardens Drive | 18 Marina Gardens Dr...  \n",
       "1  18 Marina Gardens Drive | 18 Marina Gardens Dr...  \n",
       "2      Crot | Trengganu, Singapore 048942, Singapore  \n",
       "3      Crot | Trengganu, Singapore 048942, Singapore  \n",
       "4      Marina Boulevard, Singapore 018980, Singapore  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "civic-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove acented characters\n",
    "# imports\n",
    "import unicodedata# function to remove accented characters\n",
    "def remove_accented_chars(text):\n",
    "    new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return new_text# call function\n",
    "\n",
    "import re\n",
    "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "def _get_contractions(contraction_dict):\n",
    "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
    "    return contraction_dict, contraction_re\n",
    "contractions, contractions_re = _get_contractions(contraction_dict)\n",
    "def replace_contractions(text):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "# imports\n",
    "import re# function to remove special characters\n",
    "def remove_special_characters(text):\n",
    "    # define the pattern to keep\n",
    "    pat = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
    "    return re.sub(pat, ' ', text)\n",
    " \n",
    "\n",
    "# imports\n",
    "import re# function to remove numbers\n",
    "def remove_numbers(text):\n",
    "    # define the pattern to keep\n",
    "    pattern = r'[^a-zA-z.,!?/:;\\\"\\'\\s]' \n",
    "    return re.sub(pattern, '', text)\n",
    " \n",
    "# imports\n",
    "import string# function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    text = ''.join([c for c in text if c not in string.punctuation])\n",
    "    return text# call function\n",
    "\n",
    "# imports\n",
    "import nltk\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "# custom: removing words from list\n",
    "stopword_list.remove('not')# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    # convert sentence into token of words\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    # check in lowercase \n",
    "    t = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    text = ' '.join(t)    \n",
    "    return text# call function\n",
    "\n",
    "\n",
    "# imports\n",
    "import re# function to remove special characters\n",
    "def remove_extra_whitespace_tabs(text):\n",
    "    #pattern = r'^\\s+$|\\s+$'\n",
    "    pattern = r'^\\s*|\\s\\s*'\n",
    "    return re.sub(pattern, ' ', text).strip()# call function\n",
    "\n",
    "\n",
    "# function to remove special characters\n",
    "def to_lowercase(text):\n",
    "    return text.lower()# call function\n",
    "\n",
    "\n",
    "# Lemmatize with POS Tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "# 1. Init Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def pos_lemmatizer(x):\n",
    "    x = \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(x)])\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def text_preprocessing(x):\n",
    "    ###\n",
    "    ## expanding contractions\n",
    "    x = replace_contractions(x)\n",
    "    ## remove acented characters\n",
    "    x = remove_accented_chars(x)\n",
    "    ## remove special characters\n",
    "    x = remove_special_characters(x)\n",
    "    ## remove numbers\n",
    "    x = remove_numbers(x)\n",
    "    ## remove punctuations\n",
    "    x = remove_punctuation(x)\n",
    "    ## remove stopwords\n",
    "    x = remove_stopwords(x)\n",
    "    ## remove extra white spaces\n",
    "    x = remove_extra_whitespace_tabs(x)\n",
    "    ## make lowercase\n",
    "    x = to_lowercase(x)\n",
    "    ## lemmatisation using pos\n",
    "    x = pos_lemmatizer(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "compatible-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text']= df['REVIEW_BODY'].apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "surprised-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('singapore_trip_advisor_data_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-plate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
